{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b6ed086330>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置随机种子以便复现结果\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数设置:\n",
      "  batch_size = 2, q_seq_len = 3, hidden_size = 4\n",
      "  num_experts = 3, num_topk = 2\n",
      "  num_tokens = 6, total_num_tokens = 12\n",
      "  average_num_tokens_per_expert = 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "batch_size = 2\n",
    "q_seq_len = 3\n",
    "hidden_size = 4\n",
    "num_experts = 3\n",
    "num_topk = 2  # 每个token路由到的专家数量\n",
    "\n",
    "# 计算派生参数\n",
    "num_tokens = batch_size * q_seq_len\n",
    "total_num_tokens = num_tokens * num_topk\n",
    "average_num_tokens_per_expert = total_num_tokens // num_experts\n",
    "\n",
    "print(f\"参数设置:\")\n",
    "print(f\"  batch_size = {batch_size}, q_seq_len = {q_seq_len}, hidden_size = {hidden_size}\")\n",
    "print(f\"  num_experts = {num_experts}, num_topk = {num_topk}\")\n",
    "print(f\"  num_tokens = {num_tokens}, total_num_tokens = {total_num_tokens}\")\n",
    "print(f\"  average_num_tokens_per_expert = {average_num_tokens_per_expert}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 原始输入 hidden_states:\n",
      "  形状: torch.Size([2, 3, 4]), dtype: torch.bfloat16\n",
      "tensor([[[-0.8086, -1.5312,  0.4062,  0.1719],\n",
      "         [-0.2471,  0.2041, -0.8789, -0.3867],\n",
      "         [ 0.5664,  0.2363,  0.4863,  1.1719]],\n",
      "\n",
      "        [[ 1.4531, -0.8906,  0.1543,  0.8242],\n",
      "         [-2.1719,  1.3516,  0.2754, -0.1128],\n",
      "         [-0.7969,  1.3438,  0.3750, -1.1328]]], dtype=torch.bfloat16) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 初始化输入 hidden_states\n",
    "hidden_states = torch.randn(batch_size, q_seq_len, hidden_size, dtype=torch.bfloat16)\n",
    "print(\"1. 原始输入 hidden_states:\")\n",
    "print(f\"  形状: {hidden_states.shape}, dtype: {hidden_states.dtype}\")\n",
    "print(hidden_states, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. 重塑后的 hidden_states:\n",
      "  形状: torch.Size([6, 4])\n",
      "tensor([[-0.8086, -1.5312,  0.4062,  0.1719],\n",
      "        [-0.2471,  0.2041, -0.8789, -0.3867],\n",
      "        [ 0.5664,  0.2363,  0.4863,  1.1719],\n",
      "        [ 1.4531, -0.8906,  0.1543,  0.8242],\n",
      "        [-2.1719,  1.3516,  0.2754, -0.1128],\n",
      "        [-0.7969,  1.3438,  0.3750, -1.1328]], dtype=torch.bfloat16) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. 重塑输入为 [num_tokens, hidden_size]\n",
    "reshaped_states = hidden_states.view(num_tokens, hidden_size)\n",
    "print(\"2. 重塑后的 hidden_states:\")\n",
    "print(f\"  形状: {reshaped_states.shape}\")\n",
    "print(reshaped_states, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3516,  0.6875, -0.3281],\n",
      "        [ 0.7969,  0.2812,  0.0562],\n",
      "        [ 0.5234, -0.2383, -0.0498],\n",
      "        [ 0.5273, -0.0085,  0.7305]], dtype=torch.bfloat16) \n",
      "\n",
      "3. 门控计算后的 router_logits:\n",
      "  形状: torch.Size([6, 3]), dtype: torch.bfloat16\n",
      "tensor([[-2.0156, -1.0859,  0.2852],\n",
      "        [-0.8359,  0.1001, -0.1465],\n",
      "        [ 1.8281,  0.3301,  0.6602],\n",
      "        [ 1.7734,  0.7031,  0.0674],\n",
      "        [-1.7734, -1.1797,  0.6914],\n",
      "        [-0.4082, -0.2500, -0.5078]], dtype=torch.bfloat16) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. gating gemm\n",
    "# 初始化门控权重\n",
    "gating_weight = torch.randn(hidden_size, num_experts, dtype=torch.bfloat16)\n",
    "print(gating_weight, \"\\n\")\n",
    "router_logits = torch.matmul(reshaped_states, gating_weight)\n",
    "print(\"3. 门控计算后的 router_logits:\")\n",
    "print(f\"  形状: {router_logits.shape}, dtype: {router_logits.dtype}\")\n",
    "print(router_logits, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Softmax 后的 routing_weights (float32):\n",
      "  形状: torch.Size([6, 3]), dtype: torch.float32\n",
      "tensor([[0.0740, 0.1875, 0.7385],\n",
      "        [0.1804, 0.4601, 0.3595],\n",
      "        [0.6517, 0.1457, 0.2027],\n",
      "        [0.6560, 0.2249, 0.1191],\n",
      "        [0.0686, 0.1243, 0.8071],\n",
      "        [0.3250, 0.3807, 0.2942]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Softmax 计算\n",
    "routing_weights = F.softmax(router_logits.float(), dim=1)\n",
    "print(\"4. Softmax 后的 routing_weights (float32):\")\n",
    "print(f\"  形状: {routing_weights.shape}, dtype: {routing_weights.dtype}\")\n",
    "print(routing_weights, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未进行归一化, 选择专家后的routing_weights: \n",
      "tensor([[0.7385, 0.1875],\n",
      "        [0.4601, 0.3595],\n",
      "        [0.6517, 0.2027],\n",
      "        [0.6560, 0.2249],\n",
      "        [0.8071, 0.1243],\n",
      "        [0.3807, 0.3250]]) \n",
      "\n",
      "5. Top-k 选择和归一化后的结果:\n",
      "  routing_weights:\n",
      "    形状: torch.Size([6, 2]), dtype: torch.bfloat16\n",
      "tensor([[0.7969, 0.2021],\n",
      "        [0.5625, 0.4395],\n",
      "        [0.7617, 0.2373],\n",
      "        [0.7461, 0.2559],\n",
      "        [0.8672, 0.1338],\n",
      "        [0.5391, 0.4609]], dtype=torch.bfloat16)\n",
      "\n",
      "  selected_experts:\n",
      "    形状: torch.Size([6, 2]), dtype: torch.int64\n",
      "tensor([[2, 1],\n",
      "        [1, 2],\n",
      "        [0, 2],\n",
      "        [0, 1],\n",
      "        [2, 1],\n",
      "        [1, 0]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Top-k 选择和归一化\n",
    "routing_weights, selected_experts = torch.topk(routing_weights, num_topk, dim=1)\n",
    "print(\"未进行归一化, 选择专家后的routing_weights: \")\n",
    "print(routing_weights, \"\\n\")\n",
    "routing_weights = routing_weights / routing_weights.sum(dim=1, keepdim=True)  # 归一化\n",
    "routing_weights = routing_weights.to(torch.bfloat16)\n",
    "print(\"5. Top-k 选择和归一化后的结果:\")\n",
    "print(\"  routing_weights:\")\n",
    "print(f\"    形状: {routing_weights.shape}, dtype: {routing_weights.dtype}\")\n",
    "print(routing_weights)\n",
    "print(\"\\n  selected_experts:\")\n",
    "print(f\"    形状: {selected_experts.shape}, dtype: {selected_experts.dtype}\")\n",
    "print(selected_experts, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 1, 2, 0, 2, 0, 1, 2, 1, 1, 0])\n",
      "6. 直方图统计:\n",
      " 每个专家被选到次数统计 expert_token_count: [3, 5, 4]\n",
      "\n",
      "expert_offsets:  tensor([0, 3, 8])\n",
      "  token_offsets:\n",
      "    形状[tokens, topk]: torch.Size([6, 2]), dtype: torch.int64\n",
      "tensor([[ 8,  3],\n",
      "        [ 4,  9],\n",
      "        [ 0, 10],\n",
      "        [ 1,  5],\n",
      "        [11,  6],\n",
      "        [ 7,  2]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntoken_offsets:\\n\\ntensor([[ 8,  3],\\n        [ 4,  9],\\n        [ 0, 10],\\n        [ 1,  5],\\n        [11,  6],\\n        [ 7,  2]])\\n含义：\\n[8, 3]说明: 在num_tokens中token0被专家2, 1处理, 在allocated_tokens中token的位置为8, 3。\\n\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 直方图统计和索引计算\n",
    "# 计算每个专家的 token 数量\n",
    "expert_token_count = torch.zeros(num_experts, dtype=torch.int64)\n",
    "# print(expert_token_count)\n",
    "flat_experts = selected_experts.view(-1)\n",
    "print(flat_experts)\n",
    "\"\"\"\n",
    "  selected_experts:\n",
    "    形状: torch.Size([6, 2]), dtype: torch.int64\n",
    "tensor([[2, 1],\n",
    "        [1, 2],\n",
    "        [0, 2],\n",
    "        [0, 1],\n",
    "        [2, 1],\n",
    "        [1, 0]]) \n",
    "\n",
    "flat_experts : tensor([2, 1, 1, 2, 0, 2, 0, 1, 2, 1, 1, 0])\n",
    "\"\"\"\n",
    "expert_token_count = torch.bincount(flat_experts, minlength=num_experts)  # 每个专家被选到次数统计\n",
    "\"\"\"\n",
    "统计出每个专家路由了多少token\n",
    "[3, 5, 4]\n",
    "expert0处理3个token\n",
    "expert1处理5个token\n",
    "expert2处理4个token\n",
    "\"\"\"\n",
    "\n",
    "print(\"6. 直方图统计:\")\n",
    "print(f\" 每个专家被选到次数统计 expert_token_count: {expert_token_count.tolist()}\\n\")\n",
    "\n",
    "# 计算每个专家的偏移量\n",
    "expert_offsets = torch.zeros(num_experts, dtype=torch.int64)\n",
    "expert_offsets[1:] = torch.cumsum(expert_token_count, dim=0)[:-1]\n",
    "print(\"expert_offsets: \", expert_offsets)\n",
    "\"\"\"\n",
    "expert_offsets: 专家token的偏移\n",
    "[0, 3, 8]\n",
    "3个专家总共处理12个token(token有重复)\n",
    "每个专家处理的token的偏移(token的起始索引)\n",
    "expert0处理0 ~ 3  (3个token)\n",
    "expert1处理3 ~ 8  (5个token)\n",
    "expert2处理8 ~ 12 (4个token)\n",
    "\"\"\"\n",
    "\n",
    "# 计算每个 token 在输出缓冲区的偏移\n",
    "token_offsets = torch.zeros_like(selected_experts)\n",
    "\n",
    "\"\"\"\n",
    "selected_experts: \n",
    "tensor([[2, 1],\n",
    "        [1, 2],\n",
    "        [0, 2],\n",
    "        [0, 1],\n",
    "        [2, 1],\n",
    "        [1, 0]])\n",
    "\"\"\"\n",
    "# print(token_offsets)\n",
    "for i in range(num_tokens):\n",
    "    for j in range(num_topk):\n",
    "        expert_idx = selected_experts[i, j]   # 取某个token的专家\n",
    "        token_offsets[i, j] = expert_offsets[expert_idx]  # 通过专家获得token位置\n",
    "        expert_offsets[expert_idx] += 1\n",
    "\n",
    "# 重置 expert_offsets 用于后续操作\n",
    "expert_offsets = torch.zeros(num_experts, dtype=torch.int64)\n",
    "expert_offsets[1:] = torch.cumsum(expert_token_count, dim=0)[:-1]\n",
    "\n",
    "print(\"  token_offsets:\")\n",
    "print(f\"    形状[tokens, topk]: {token_offsets.shape}, dtype: {token_offsets.dtype}\")\n",
    "print(token_offsets, \"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "token_offsets:\n",
    "\n",
    "tensor([[ 8,  3],\n",
    "        [ 4,  9],\n",
    "        [ 0, 10],\n",
    "        [ 1,  5],\n",
    "        [11,  6],\n",
    "        [ 7,  2]])\n",
    "含义：\n",
    "[8, 3]说明: 在num_tokens中token0被专家2, 1处理, 在allocated_tokens中token的位置为8, 3。\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. 分散后的 prepared_tokens:\n",
      "  形状: torch.Size([12, 4]), dtype: torch.bfloat16\n",
      "tensor([[ 0.5664,  0.2363,  0.4863,  1.1719],\n",
      "        [ 1.4531, -0.8906,  0.1543,  0.8242],\n",
      "        [-0.7969,  1.3438,  0.3750, -1.1328],\n",
      "        [-0.8086, -1.5312,  0.4062,  0.1719],\n",
      "        [-0.2471,  0.2041, -0.8789, -0.3867],\n",
      "        [ 1.4531, -0.8906,  0.1543,  0.8242],\n",
      "        [-2.1719,  1.3516,  0.2754, -0.1128],\n",
      "        [-0.7969,  1.3438,  0.3750, -1.1328],\n",
      "        [-0.8086, -1.5312,  0.4062,  0.1719],\n",
      "        [-0.2471,  0.2041, -0.8789, -0.3867],\n",
      "        [ 0.5664,  0.2363,  0.4863,  1.1719],\n",
      "        [-2.1719,  1.3516,  0.2754, -0.1128]], dtype=torch.bfloat16) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. 分散 (Scatter) 操作\n",
    "# 准备缓冲区\n",
    "prepared_tokens = torch.zeros(total_num_tokens, hidden_size, dtype=torch.bfloat16)\n",
    "\n",
    "# 分散数据\n",
    "for i in range(num_tokens):\n",
    "    for j in range(num_topk):\n",
    "        offset = token_offsets[i, j]\n",
    "        prepared_tokens[offset] = reshaped_states[i]\n",
    "\n",
    "print(\"7. 分散后的 prepared_tokens:\")\n",
    "print(f\"  形状: {prepared_tokens.shape}, dtype: {prepared_tokens.dtype}\")\n",
    "print(prepared_tokens, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.5664,  0.2363,  0.4863,  1.1719],\n",
      "        [ 1.4531, -0.8906,  0.1543,  0.8242],\n",
      "        [-0.7969,  1.3438,  0.3750, -1.1328]], dtype=torch.bfloat16), tensor([[-0.8086, -1.5312,  0.4062,  0.1719],\n",
      "        [-0.2471,  0.2041, -0.8789, -0.3867],\n",
      "        [ 1.4531, -0.8906,  0.1543,  0.8242],\n",
      "        [-2.1719,  1.3516,  0.2754, -0.1128],\n",
      "        [-0.7969,  1.3438,  0.3750, -1.1328]], dtype=torch.bfloat16), tensor([[-0.8086, -1.5312,  0.4062,  0.1719],\n",
      "        [-0.2471,  0.2041, -0.8789, -0.3867],\n",
      "        [ 0.5664,  0.2363,  0.4863,  1.1719],\n",
      "        [-2.1719,  1.3516,  0.2754, -0.1128]], dtype=torch.bfloat16)] \n",
      "\n",
      "8. 专家处理后的 output_tokens:\n",
      "  形状: torch.Size([12, 4]), dtype: torch.bfloat16\n",
      "tensor([[-1.3672,  1.6328, -1.1641,  4.1562],\n",
      "        [-1.8750, -0.5273,  2.5156,  2.3594],\n",
      "        [ 4.0938, -0.1484, -2.5781,  1.1016],\n",
      "        [ 1.5391, -0.4023, -0.4805,  0.2188],\n",
      "        [ 1.5859, -0.2832,  0.9688,  1.2266],\n",
      "        [ 9.6875,  9.8125,  1.0234, -2.7500],\n",
      "        [-0.2676,  3.5781, -3.1250,  2.6406],\n",
      "        [-1.5547,  1.4766, -1.3906,  4.5938],\n",
      "        [-2.0156, -0.6797,  0.7422,  2.1094],\n",
      "        [ 1.3516, -0.2295, -0.4844, -0.5859],\n",
      "        [ 4.9375, -3.9531, -1.0391,  0.4590],\n",
      "        [-2.3281, -1.9375,  5.5625, -0.4473]], dtype=torch.bfloat16) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. 分组矩阵乘法 (Grouped GEMM)\n",
    "# 初始化专家权重\n",
    "expert_weights1 = torch.randn(num_experts, hidden_size, hidden_size * 2, dtype=torch.bfloat16)\n",
    "expert_weights2 = torch.randn(num_experts, hidden_size * 2, hidden_size, dtype=torch.bfloat16)\n",
    "\n",
    "# 准备专家输入缓冲区\n",
    "expert_inputs = []\n",
    "for i in range(num_experts):\n",
    "    start = expert_offsets[i]\n",
    "    end = start + expert_token_count[i]\n",
    "    expert_inputs.append(prepared_tokens[start:end])\n",
    "\n",
    "print(expert_inputs, \"\\n\")\n",
    "\n",
    "# 专家处理\n",
    "expert_outputs = []\n",
    "for i in range(num_experts):\n",
    "    if expert_token_count[i] > 0:\n",
    "        # 第一层线性变换\n",
    "        hidden = torch.matmul(expert_inputs[i], expert_weights1[i])\n",
    "        # 激活函数\n",
    "        hidden = F.gelu(hidden)\n",
    "        # 第二层线性变换\n",
    "        output = torch.matmul(hidden, expert_weights2[i])\n",
    "        expert_outputs.append(output)\n",
    "    else:\n",
    "        expert_outputs.append(torch.zeros(0, hidden_size, dtype=torch.bfloat16))\n",
    "\n",
    "# 收集所有专家输出\n",
    "output_tokens = torch.cat(expert_outputs, dim=0)\n",
    "print(\"8. 专家处理后的 output_tokens:\")\n",
    "print(f\"  形状: {output_tokens.shape}, dtype: {output_tokens.dtype}\")\n",
    "print(output_tokens, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9. 收集后的 final_results:\n",
      "  形状[num_tokens, hidden_size]: torch.Size([6, 4]), dtype: torch.bfloat16\n",
      "tensor([[-1.2969, -0.6250,  0.4922,  1.7266],\n",
      "        [ 1.4844, -0.2598,  0.3340,  0.4336],\n",
      "        [ 0.1328,  0.3047, -1.1328,  3.2812],\n",
      "        [ 1.0859,  2.1250,  2.1406,  1.0547],\n",
      "        [-2.0469, -1.2031,  4.4062, -0.0352],\n",
      "        [ 1.0469,  0.7266, -1.9375,  2.9688]], dtype=torch.bfloat16) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. 收集(Gather) 操作\n",
    "# 创建最终结果缓冲区\n",
    "final_results = torch.zeros(num_tokens, hidden_size, dtype=torch.bfloat16)\n",
    "\n",
    "# 收集并加权求和\n",
    "for i in range(num_tokens):\n",
    "    for j in range(num_topk):\n",
    "        offset = token_offsets[i, j]\n",
    "        final_results[i] += routing_weights[i, j] * output_tokens[offset]\n",
    "\n",
    "print(\"9. 收集后的 final_results:\")\n",
    "print(f\"  形状[num_tokens, hidden_size]: {final_results.shape}, dtype: {final_results.dtype}\")\n",
    "print(final_results, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10. 最终输出 final_output:\n",
      "  形状: torch.Size([2, 3, 4])\n",
      "tensor([[[-1.2969, -0.6250,  0.4922,  1.7266],\n",
      "         [ 1.4844, -0.2598,  0.3340,  0.4336],\n",
      "         [ 0.1328,  0.3047, -1.1328,  3.2812]],\n",
      "\n",
      "        [[ 1.0859,  2.1250,  2.1406,  1.0547],\n",
      "         [-2.0469, -1.2031,  4.4062, -0.0352],\n",
      "         [ 1.0469,  0.7266, -1.9375,  2.9688]]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# 10. 恢复原始形状\n",
    "final_output = final_results.view(batch_size, q_seq_len, hidden_size)\n",
    "print(\"10. 最终输出 final_output:\")\n",
    "print(f\"  形状: {final_output.shape}\")\n",
    "print(final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
